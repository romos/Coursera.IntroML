{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_orig = pandas.read_csv('../data/features.csv',index_col='match_id')\n",
    "features_test_orig = pandas.read_csv('../data/features_test.csv',index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Удаляем признаки, связанные с итогами матча "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = features_orig\n",
    "features_test = features_test_orig\n",
    "\n",
    "for c in ['duration',\n",
    "#           'radiant_win',\n",
    "          'tower_status_radiant',\n",
    "          'tower_status_dire',\n",
    "          'barracks_status_radiant',\n",
    "          'barracks_status_dire']:\n",
    "    if c in features.columns:\n",
    "        features = features.drop(c,axis=1)\n",
    "    if c in features_test.columns:\n",
    "        features_test = features_test.drop(c,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем пропуски среди оставшихся признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_blood_time               77677\n",
       "first_blood_team               77677\n",
       "first_blood_player1            77677\n",
       "first_blood_player2            53243\n",
       "radiant_bottle_time            81539\n",
       "radiant_courier_time           96538\n",
       "radiant_flying_courier_time    69751\n",
       "radiant_first_ward_time        95394\n",
       "dire_bottle_time               81087\n",
       "dire_courier_time              96554\n",
       "dire_flying_courier_time       71132\n",
       "dire_first_ward_time           95404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.count()[features.count() < features.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем 12 фич\n",
    "\n",
    "4 относятся к событию first blood:  \n",
    "\n",
    "**first_blood_time               77677**  \n",
    "время самого первого убийства соперника (независимо от команды). Может не произойти за первые 5 минут, поэтому может быть пропущено в выборке.  \n",
    "**first_blood_team               77677**  \n",
    "команда, игрок который совершил first blood.  \n",
    "**first_blood_player1            77677**  \n",
    "**first_blood_player2            53243**  \n",
    "пара игроков, причастных к first blood  \n",
    "\n",
    "8 событий относятся к каждой команде в отдельности.\n",
    "Если они не попадают в первые 5 минут, то в выборке образуется пропуск.\n",
    "\n",
    "**radiant_bottle_time            81539**  \n",
    "время покупки предмета 'bottle', который позволяет восстанавливать здоровье и ману Героев, а также хранить руны  \n",
    "**radiant_courier_time           96538**  \n",
    "время приборетения \"courier\" - предмета, позволяющего транспортировать предметы  \n",
    "**radiant_flying_courier_time    69751**  \n",
    "время приборетения \"flying_courier\" - предмета, позволяющего транспортировать предметы. Особая разновидность flying  \n",
    "**radiant_first_ward_time        95394**  \n",
    "время установки командой первого \"наблюдателя\", т.е. предмета, который позволяет видеть часть игрового поля  \n",
    "\n",
    "Аналогичные характеристики логируются и для второй команды:  \n",
    "**dire_bottle_time               81087**  \n",
    "**dire_courier_time              96554**  \n",
    "**dire_flying_courier_time       71132**  \n",
    "**dire_first_ward_time           95404**  \n",
    "\n",
    "Теоретически, существует возможность и того, что соответствующие покупки предметов или события вообще не имели места, но это практически невозможно с учетом особенностей игры Dota 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем пропуски в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Заменить пропуски на нули - самый простой вариант.\n",
    "# Рекомендован при использовании логистической регрессии,\n",
    "# т.к. пропущенное значение перестает влиять на предсказание. \n",
    "features = features.fillna(0)\n",
    "features_test = features_test.fillna(0)\n",
    "\n",
    "### Можно пробовать заменить на очень большое или очень маленькое значение.\n",
    "### Это полезно для деревьев: благодаря этому получается отнести объекты с пропусками в отдельную ветвь дерева\n",
    "# features = features.fillna(999999999)\n",
    "# features_test = features_test.fillna(999999999)\n",
    "\n",
    "### Можно пробовать заменить на среднее значение столбца.\n",
    "# features = features.fillna(features.mean())\n",
    "# features_test = features_test.fillna(features_test.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель - предсказать значение признака **radiant_win**  \n",
    "0 - если победила команда Dire  \n",
    "1 - если победила команда Radiant  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features.iloc[:, :-1].values\n",
    "y = features.iloc[:, -1:].values.ravel()\n",
    "N = len(y)\n",
    "\n",
    "X_test = features_test.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvkfold = cross_validation.KFold(N,\n",
    "                           n_folds=5,\n",
    "                           shuffle=True,\n",
    "                           random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Можно сделать подбор нужного кол-ва деревьев с помощью cross_val_score и передать туда метрику.\n",
    "#\n",
    "# print(\"Gradient Boosting. CrossValScore\")\n",
    "# trees = [10,20,30]\n",
    "# for t in trees:\n",
    "#     gbclf = GradientBoostingClassifier(n_estimators=t,\n",
    "#                                       # verbose=True,\n",
    "#                                       random_state=241)\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     cvscores = cross_validation.cross_val_score(gbclf, X, y, scoring='roc_auc', cv=cvkfold)\n",
    "#     elapsed_seconds = (datetime.datetime.now() - start_time).total_seconds()   \n",
    "#     avgcvscore = np.mean(cvscores)\n",
    "#     print('Trees: %d\\t Avg Score: %.5f\\t Elapsed Time: %d' % (t, avgcvscore, elapsed_seconds))\n",
    "\n",
    "#\n",
    "# Можно \"руками сделать все, что нужно для подсчет AUC_ROC:\n",
    "#\n",
    "print(\"Gradient Boosting. Manual CrossValScore\")\n",
    "trees = [10,20,30]\n",
    "for t in trees:\n",
    "    gbclf = GradientBoostingClassifier(n_estimators=t,\n",
    "                                      # verbose=True,\n",
    "                                      random_state=241)\n",
    "    auc_roc_metrics = []\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for (train, test) in cvkfold:\n",
    "        gbclf.fit(X[train], y[train])\n",
    "        pred = gbclf.predict_proba(X[test])[:,1]\n",
    "        auc_roc_metrics.append(roc_auc_score(y[test],pred))\n",
    "    \n",
    "    elapsed_seconds = (datetime.datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    auc_roc_metrics_avg = np.mean(auc_roc_metrics)    \n",
    "    print('Trees: %d\\t Avg Score: %.5f\\t Elapsed Time: %d' % (t, auc_roc_metrics_avg, elapsed_seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получается следующий результат:**  \n",
    "Trees: 10    Avg Score: 0.66439    Elapsed Time: 52  \n",
    "Trees: 20    Avg Score: 0.68285    Elapsed Time: 102  \n",
    "Trees: 30    Avg Score: 0.68950    Elapsed Time: 151  \n",
    "  \n",
    "Градиентный бустинг, конечно, может переобучаться, и, возможно, если позволяли бы ресурсы, можно чуть больше обучить его.  \n",
    "Однако результат не станет сильно лучше.  \n",
    "  \n",
    "Для улучшения работы бустинга можно порпобовать:  \n",
    "* подбирать число дереьев  \n",
    "* ограничить глубину деревьев и другие параметры\n",
    "* заполнять пропуски в данных не просто нулями, а оч.большими или маленькими значениями, чтобы соответствующие объекты скорее уходили в крайние ветви деревьев\n",
    "и т.п.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t = 30\n",
    "# gbclf = GradientBoostingClassifier(n_estimators=t,\n",
    "#                                   verbose=True,\n",
    "#                                   random_state=241)\n",
    "# gbclf.fit(X,y)\n",
    "# # pred = gbclf.predict_proba(X_test)\n",
    "# pred = gbclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_scl=scale.fit_transform(X)\n",
    "X_test_scl = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression w/L2 regularization\n",
      "C: 0.0000100000\t Avg Score: 0.6951203798\t Elapsed Time: 2\n",
      "C: 0.0001000000\t Avg Score: 0.7112501165\t Elapsed Time: 3\n",
      "C: 0.0010000000\t Avg Score: 0.7161802464\t Elapsed Time: 7\n",
      "C: 0.0100000000\t Avg Score: 0.7163414685\t Elapsed Time: 10\n",
      "C: 0.1000000000\t Avg Score: 0.7163100858\t Elapsed Time: 10\n",
      "C: 1.0000000000\t Avg Score: 0.7163065858\t Elapsed Time: 10\n",
      "C: 10.0000000000\t Avg Score: 0.7163063357\t Elapsed Time: 10\n",
      "C: 100.0000000000\t Avg Score: 0.7163062647\t Elapsed Time: 10\n",
      "C: 1000.0000000000\t Avg Score: 0.7163062584\t Elapsed Time: 10\n",
      "C: 10000.0000000000\t Avg Score: 0.7163062552\t Elapsed Time: 10\n",
      "C: 100000.0000000000\t Avg Score: 0.7163062552\t Elapsed Time: 10\n",
      "Optimal C:  0.01 Optimal AUC_ROC:  0.716341468544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Linear Regression w/L2 regularization\")\n",
    "\n",
    "Cs = np.power(10.0, np.arange(-5,6))\n",
    "C_optimal = Cs[0]\n",
    "AUC_ROC_optimal = 0\n",
    "for C in Cs:\n",
    "    lgclf = LogisticRegression(random_state=241, penalty='l2',C=C)\n",
    "    auc_roc_metrics = []\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for (train, test) in cvkfold:\n",
    "        lgclf.fit(X_scl[train], y[train])\n",
    "        pred = lgclf.predict_proba(X_scl[test])[:,1]\n",
    "        auc_roc_metrics.append(roc_auc_score(y[test],pred))\n",
    "    \n",
    "    elapsed_seconds = (datetime.datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    auc_roc_metrics_avg = np.mean(auc_roc_metrics)    \n",
    "    if auc_roc_metrics_avg > AUC_ROC_optimal:\n",
    "        C_optimal = C\n",
    "        AUC_ROC_optimal = auc_roc_metrics_avg\n",
    "\n",
    "    print('C: %.10f\\t Avg Score: %.10f\\t Elapsed Time: %d' % (C, auc_roc_metrics_avg, elapsed_seconds))\n",
    "    \n",
    "print('Optimal C: ', C_optimal, 'Optimal AUC_ROC: ', AUC_ROC_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal C:  0.01 Optimal AUC_ROC:  0.716341468544\n",
    "\n",
    "Таким образом, видно, что при C = 0.01 точность является максимальной (среди рассмотренных).  \n",
    "Скорость Лог.Рег. на порядок выше Град.Бустинга, а точность одновременно превосходит Град.Бустинг. \n",
    "Линейные методы в общем случае больше пригодны для разреженных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим категориальные признаки (те, которые принимают значения из конечного множества) и проверим, изменится ли качество Лог.Регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r1_hero', 'd1_hero', 'r2_hero', 'd2_hero', 'r3_hero', 'd3_hero', 'r4_hero', 'd4_hero', 'r5_hero', 'd5_hero', 'lobby_hero']\n"
     ]
    }
   ],
   "source": [
    "features_nocateg = features\n",
    "features_test_nocateg = features_test\n",
    "\n",
    "cols = []\n",
    "for i in range(1,6):\n",
    "    cols.append('r%d_hero' % (i))\n",
    "    cols.append('d%d_hero' % (i))\n",
    "cols.append('lobby_hero')\n",
    "\n",
    "print(cols)\n",
    "\n",
    "for c in cols:\n",
    "    if c in features_nocateg.columns:\n",
    "        features_nocateg = features_nocateg.drop(c,axis=1)\n",
    "    if c in features_test_nocateg.columns:\n",
    "        features_test_nocateg = features_test_nocateg.drop(c,axis=1)\n",
    "\n",
    "X_nocateg = features_nocateg.iloc[:, :-1].values\n",
    "y = features_nocateg.iloc[:, -1:].values.ravel()\n",
    "N = len(y)\n",
    "\n",
    "X_test_nocateg = features_test_nocateg.iloc[:, :].values\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_nocateg_scl=scale.fit_transform(X_nocateg)\n",
    "X_test_nocateg_scl = scale.transform(X_test_nocateg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression w/L2 regularization\n",
      "C: 0.0000100000\t Avg Score: 0.6950753446\t Elapsed Time: 2\n",
      "C: 0.0001000000\t Avg Score: 0.7112459610\t Elapsed Time: 3\n",
      "C: 0.0010000000\t Avg Score: 0.7162245080\t Elapsed Time: 7\n",
      "C: 0.0100000000\t Avg Score: 0.7163869752\t Elapsed Time: 9\n",
      "C: 0.1000000000\t Avg Score: 0.7163591262\t Elapsed Time: 9\n",
      "C: 1.0000000000\t Avg Score: 0.7163559913\t Elapsed Time: 10\n",
      "C: 10.0000000000\t Avg Score: 0.7163555285\t Elapsed Time: 9\n",
      "C: 100.0000000000\t Avg Score: 0.7163554978\t Elapsed Time: 9\n",
      "C: 1000.0000000000\t Avg Score: 0.7163555126\t Elapsed Time: 9\n",
      "C: 10000.0000000000\t Avg Score: 0.7163555105\t Elapsed Time: 10\n",
      "C: 100000.0000000000\t Avg Score: 0.7163555063\t Elapsed Time: 10\n",
      "Optimal C:  0.01 Optimal AUC_ROC:  0.716386975157\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression w/L2 regularization\")\n",
    "\n",
    "Cs = np.power(10.0, np.arange(-5,6))\n",
    "C_optimal = Cs[0]\n",
    "AUC_ROC_optimal = 0\n",
    "for C in Cs:\n",
    "    lgclf = LogisticRegression(random_state=241, penalty='l2',C=C)\n",
    "    auc_roc_metrics = []\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for (train, test) in cvkfold:\n",
    "        lgclf.fit(X_nocateg_scl[train], y[train])\n",
    "        pred = lgclf.predict_proba(X_nocateg_scl[test])[:,1]\n",
    "        auc_roc_metrics.append(roc_auc_score(y[test],pred))\n",
    "    \n",
    "    elapsed_seconds = (datetime.datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    auc_roc_metrics_avg = np.mean(auc_roc_metrics)    \n",
    "    if auc_roc_metrics_avg > AUC_ROC_optimal:\n",
    "        C_optimal = C\n",
    "        AUC_ROC_optimal = auc_roc_metrics_avg\n",
    "\n",
    "    print('C: %.10f\\t Avg Score: %.10f\\t Elapsed Time: %d' % (C, auc_roc_metrics_avg, elapsed_seconds))\n",
    "    \n",
    "print('Optimal C: ', C_optimal, 'Optimal AUC_ROC: ', AUC_ROC_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С учетом того, что мы перестали учитывать категориальные признаки, качество практически не изменилось. И в предыдущем случае, и сейчас мы неправильно учитывали эти признаки - считали их простыми числовыми.  \n",
    "Стоило ввести мешок слов, чтобы сохранить их для алгоритма, но сделать их использование более разумным.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А сколько всего существует различных героев в нашей оригинальной выборке?  \n",
    "Возьмем все столбцы с героями и найдем среди всех значений уникальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 109 110 112]\n"
     ]
    }
   ],
   "source": [
    "cols = []\n",
    "for i in range(1,6):\n",
    "    cols.append('r%d_hero' % (i))\n",
    "    cols.append('d%d_hero' % (i))\n",
    "\n",
    "heroes = features[cols].values\n",
    "unique_heroes = np.unique(heroes)\n",
    "print(unique_heroes)\n",
    "\n",
    "# unique_heroes_stat = pandas.Series(heroes.ravel(),index=range(0,len(heroes.ravel()))).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что не все герои фигурируют в данных. Но в любом случае, максимум их тут 112.\n",
    "Теперь построим bag of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N — количество различных героев в выборке\n",
    "N = np.max(unique_heroes)\n",
    "X_pick = np.zeros((features.shape[0], N))\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features[('r%d_hero' % (p+1))].iloc[i] - 1] = 1\n",
    "        X_pick[i, features[('d%d_hero' % (p+1))].iloc[i] - 1] = -1\n",
    "        \n",
    "        \n",
    "X_pick_test = np.zeros((features_test.shape[0], N))\n",
    "for i, match_id in enumerate(features_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick_test[i, features_test[('r%d_hero' % (p+1))].iloc[i] - 1] = 1\n",
    "        X_pick_test[i, features_test[('d%d_hero' % (p+1))].iloc[i] - 1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_bag_scl = np.hstack((X_nocateg_scl, X_pick))\n",
    "X_test_bag_scl = np.hstack((X_test_nocateg_scl, X_pick_test))\n",
    "y = features_nocateg.iloc[:, -1:].values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова проведем лог.регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression w/L2 regularization\n",
      "C: 0.0000100000\t Avg Score: 0.6991841196\t Elapsed Time: 2\n",
      "C: 0.0001000000\t Avg Score: 0.7250149759\t Elapsed Time: 4\n",
      "C: 0.0010000000\t Avg Score: 0.7462791442\t Elapsed Time: 8\n",
      "C: 0.0100000000\t Avg Score: 0.7517215526\t Elapsed Time: 14\n",
      "C: 0.1000000000\t Avg Score: 0.7519199665\t Elapsed Time: 19\n",
      "C: 1.0000000000\t Avg Score: 0.7519031340\t Elapsed Time: 20\n",
      "C: 10.0000000000\t Avg Score: 0.7519014761\t Elapsed Time: 20\n",
      "C: 100.0000000000\t Avg Score: 0.7519012463\t Elapsed Time: 20\n",
      "C: 1000.0000000000\t Avg Score: 0.7519013903\t Elapsed Time: 20\n",
      "C: 10000.0000000000\t Avg Score: 0.7519011361\t Elapsed Time: 21\n",
      "C: 100000.0000000000\t Avg Score: 0.7519009220\t Elapsed Time: 20\n",
      "Optimal C:  0.1 Optimal AUC_ROC:  0.751919966491\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression w/L2 regularization\")\n",
    "\n",
    "Cs = np.power(10.0, np.arange(-5,6))\n",
    "C_optimal = Cs[0]\n",
    "AUC_ROC_optimal = 0\n",
    "for C in Cs:\n",
    "    lgclf = LogisticRegression(random_state=241, penalty='l2',C=C)\n",
    "    auc_roc_metrics = []\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for (train, test) in cvkfold:\n",
    "        lgclf.fit(X_bag_scl[train], y[train])\n",
    "        pred = lgclf.predict_proba(X_bag_scl[test])[:,1]\n",
    "        auc_roc_metrics.append(roc_auc_score(y[test],pred))\n",
    "    \n",
    "    elapsed_seconds = (datetime.datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    auc_roc_metrics_avg = np.mean(auc_roc_metrics)    \n",
    "    if auc_roc_metrics_avg > AUC_ROC_optimal:\n",
    "        C_optimal = C\n",
    "        AUC_ROC_optimal = auc_roc_metrics_avg\n",
    "\n",
    "    print('C: %.10f\\t Avg Score: %.10f\\t Elapsed Time: %d' % (C, auc_roc_metrics_avg, elapsed_seconds))\n",
    "    \n",
    "print('Optimal C: ', C_optimal, 'Optimal AUC_ROC: ', AUC_ROC_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что теперь качество регрессии улучшилось.  \n",
    "Оптимальные настройки регрессии:  \n",
    "Optimal C:  0.1 Optimal AUC_ROC:  0.751919966491  \n",
    "Благодаря более корректному спользованию категориальных признаков в сочетании с нормализацией остальных числовых признаков мы получили более эффективный классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь протестируем на тестовых данных Логистич. Регрессию с параметром C=0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression w/L2 regularization\n",
      "C: 0.1000000000\t Elapsed Time: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression w/L2 regularization\")\n",
    "\n",
    "C = 0.1\n",
    "lgclf = LogisticRegression(random_state=241, penalty='l2',C=C)\n",
    "start_time = datetime.datetime.now()\n",
    "lgclf.fit(X_bag_scl, y)\n",
    "pred = lgclf.predict(X_test_bag_scl)\n",
    "pred_prob = lgclf.predict_proba(X_test_bag_scl)[:,1]\n",
    "elapsed_seconds = (datetime.datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print('C: %.10f\\t Elapsed Time: %d' % (C, elapsed_seconds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальные и максимальные вероятности, полученные на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX prob: 0.996383219816\n",
      "MIN prob: 0.00841018475324\n"
     ]
    }
   ],
   "source": [
    "print('MAX prob:', np.max(pred_prob))\n",
    "print('MIN prob:', np.min(pred_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
